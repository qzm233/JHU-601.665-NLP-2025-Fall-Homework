INFO:probs:Read vocab of size 3439 from genspam-vocab.txt
INFO:train_lm:Training...
INFO:probs:Start optimizing on {N} training tokens...
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 1: F = -5.7366524871
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 2: F = -4.7270872019
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 3: F = -4.4111859941
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 4: F = -4.2236525068
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 5: F = -4.0923969234
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 6: F = -3.9926111620
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 7: F = -3.9127884883
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 8: F = -3.8466951274
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 9: F = -3.7905724754
total 23268
checkpoint at 10000
checkpoint at 20000
epoch 10: F = -3.7419845065
Finished training on 23268 tokens
INFO:probs:done optimizing.
INFO:probs:Saving model to spam_C0.5_d200.model
INFO:probs:Saved model to spam_C0.5_d200.model
