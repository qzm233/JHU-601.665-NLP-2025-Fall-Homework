INFO:probs:Read vocab of size 84 from vocab-ensp.txt
INFO:train_lm:Training...
INFO:probs:Start optimizing on {N} training tokens...
total 1027
epoch 1: F = -4.3814369395
total 1027
epoch 2: F = -4.2953550303
total 1027
epoch 3: F = -4.2254310269
total 1027
epoch 4: F = -4.1680358826
total 1027
epoch 5: F = -4.1204092712
total 1027
epoch 6: F = -4.0804601264
total 1027
epoch 7: F = -4.0466000117
total 1027
epoch 8: F = -4.0176150302
total 1027
epoch 9: F = -3.9925701834
total 1027
epoch 10: F = -3.9707386768
Finished training on 1027 tokens
INFO:probs:done optimizing.
INFO:probs:Saving model to en_C0.1_d10.model
INFO:probs:Saved model to en_C0.1_d10.model
